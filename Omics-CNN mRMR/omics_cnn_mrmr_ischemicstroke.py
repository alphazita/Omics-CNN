# -*- coding: utf-8 -*-
"""Omics-CNN mRMR IschemicStroke

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m1-7BdLtgGCcBPB7JtdLGTAzyNzwYuNN
"""

!pip install Biopython
!pip install git+https://github.com/danielhomola/mifs
!pip install joblib
#η βιβλιοθήκη στο package θέλει joblib χωρίς sklearn γιατί πετάει error
#from joblib.parallel import cpu_count

from google.colab import files 
uploaded = files.upload()

!apt install sklearn.feature_selection.base

import pandas as pd
import numpy as np
import io
ds=pd.read_excel(io.BytesIO(uploaded['combined_stroke_normalized.xlsx']))
ds.iloc[1,0]='Results'
headers=ds.iloc[1:,0].tolist()
dataFrame=pd.DataFrame(np.transpose(ds.iloc[1:,1:]).values[:],columns=headers)
X=dataFrame.drop('Results',axis=1) 
Y=dataFrame['Results']
print(dataFrame)

#Εφαρμόζουμε mRMR-test
#def __init__(self, method='MRMR', k=5, n_features='auto', categorical=True,n_jobs=1, verbose=1):
import mifs

from sklearn import preprocessing
lb = preprocessing.LabelBinarizer()
Y=lb.fit_transform(Y)
Y=Y.ravel()

# define MI_FS feature selection method
feat_selector = mifs.MutualInformationFeatureSelector(method='MRMR',k=7,n_features='auto',categorical=True,verbose=2)

# find all relevant features
feat_selector.fit(X,Y)
print(feat_selector.ranking_)
X_filtered = feat_selector.transform(X)
print('Number of samples',len(X_filtered))
print('Number of genes of each sample',len(X_filtered[0]))

data=[]
columns=dataFrame.columns.tolist()
#columns.remove('Results')
dataFrame_new=np.transpose(dataFrame)
list=[12217, 12474, 11934, 4407, 9526, 610, 7127, 5183, 10980, 6653, 5543, 11674, 5913, 713, 4447]
list2=['UBE2F','VPRBP','TRHR','GNE','RLN2','AP1M1','MYT1L','ICA1L','ST8SIA4','MFAP4','ITSN1','TNFRSF4','KRT15','ARFIP2','GORASP2']
for i in list:
  k=i-1
  values=dataFrame.iloc[:,k]
  zipped=zip(list2, values) 
  a_dictionary = dict(zipped)
  data.append(values)
ds_new=pd.DataFrame(data)
print(ds_new)

from scipy.cluster.hierarchy import dendrogram, linkage
from plotly.offline import init_notebook_mode, iplot
from Bio.Cluster import treecluster 
import plotly.graph_objs as go
import numpy as np
import matplotlib.pyplot as plt
from collections import Counter, defaultdict

D=ds_new
Z = linkage(D, method='ward', metric='euclidean')
plt.figure(figsize=(10, 6))
ax = plt.subplot()
plt.subplots_adjust(left=0.07, bottom=0.3, right=0.98, top=0.95,wspace=0, hspace=0)
plt.xlabel('Genes')
plt.ylabel('Distance')
d=dendrogram(Z, leaf_rotation=90., leaf_font_size=10.)

from scipy.cluster.hierarchy import leaves_list
list=leaves_list(Z)
print(list)
print (len(list))

import tensorflow as tf
import pandas as pd
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import EarlyStopping,LearningRateScheduler
import keras
from tensorflow.python.keras.layers import Dense,Dropout, Flatten,Conv1D, AveragePooling1D,InputLayer,MaxPooling1D
#from tensorflow.python.keras.optimizers import SGD
from tensorflow.python.keras import Sequential
import numpy as np
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import classification_report
from keras.utils import np_utils
import datetime

df=np.transpose(ds_new)
columns=[list2[i] for i in list]
data=[]

for i in list:
  values=df.iloc[:,i]
  data.append(values)
ds_new=np.transpose(pd.DataFrame(data,columns))
ds_new['Results']=dataFrame['Results'].values[:]

genes=ds_new.columns.values.tolist()

# learning rate schedule
import math
#LearningRate = InitialLearningRate * DropRate^floor(Epoch / EpochDrop),floor=the integer not greater than Epoch/EpochDrop
def step_decay(epoch):
	initial_lrate = 0.01
	drop = 0.5
	epochs_drop = 100.0
	lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))
	return lrate
from tensorflow.python.framework.ops import disable_eager_execution

#disable_eager_execution()
#input_shape = (X_test.shape)


model = Sequential()

model.add(Conv1D(filters=64,kernel_size=10, strides=1,activation= 'relu',input_shape=(15,1),padding='same'))
model.add(Dropout(0.2))
model.add(MaxPooling1D(pool_size=2))
model.add(Dense(units=500, activation='relu'))
model.add(Dense(units=250, activation='relu'))
model.add(Flatten())
model.add(Dropout(0.2))
model.add(Dense(units=134, activation='relu'))
model.add(Dense(units=2, activation = 'softmax'))

# learning schedule callback
lrate = LearningRateScheduler(step_decay)
# Compile model
print(model.summary())
model.compile( loss='sparse_categorical_crossentropy' , optimizer='sgd', metrics=[ 'accuracy' ])
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)

# Κάνω Stratified Cross Validation για την αξιολόγηση του μοντέλου
from sklearn import model_selection
import matplotlib.pyplot as plt
from scipy import interp
from sklearn.metrics import roc_curve, auc
from sklearn import preprocessing


lb = preprocessing.LabelBinarizer()
Y=ds_new['Results']
Y=lb.fit_transform(Y)
X=ds_new.drop(['Results'],axis=1)

k_fold = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)
X=X.values.reshape(X.shape[0],X.shape[1],1)
cvscores=[]

mean_tpr = 0.0
mean_fpr = np.linspace(0, 1, 100)
all_tpr = []
model2=model
i=0

for k_train_index, k_test_index in k_fold.split(X, Y):
  history=model.fit(X[k_train_index,:], Y[k_train_index],validation_data=(X[k_test_index,:],Y[k_test_index]) ,epochs=400,batch_size=30,callbacks=[lrate,es])
  results = model.evaluate(X[k_train_index,:], Y[k_train_index], verbose=0)
  probas_ =model.predict_proba(X[k_test_index,:])
  results = model.evaluate(X[k_train_index,:], Y[k_train_index], verbose=0)
  print('train loss,train acc: ',results)
  results = model.evaluate(X[k_test_index,:],Y[k_test_index], batch_size=30)
  print('test loss, test acc:', results)
  cvscores.append(results[1] * 100)
  # Compute ROC curve and area the curve
  fpr, tpr, thresholds = roc_curve(Y[k_test_index], probas_[:, 1])
  mean_tpr += interp(mean_fpr, fpr, tpr)
  mean_tpr[0] = 0.0
  roc_auc = auc(fpr, tpr)
  plt.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))
  i=i+1

plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')
mean_tpr /= 5
mean_tpr[-1] = 1.0
mean_auc = auc(mean_fpr, mean_tpr)
plt.plot(mean_fpr, mean_tpr, 'k--',label='Mean ROC (area = %0.2f)' % mean_auc, lw=2)

plt.xlim([-0.05, 1.05])
plt.ylim([-0.05, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.show()
##########
  

val_loss, val_acc = model.evaluate(X, Y)
print('Model accuracy of whole dataset as test dataset',val_acc)
y_pred = model.predict(X, batch_size=10, verbose=1)
y_pred_bool = np.argmax(y_pred, axis=1)
print(classification_report(Y, y_pred_bool))
print("Mean performance of model %.2f%% (+/- %.2f%%)" % (np.mean(cvscores), np.std(cvscores)))

example=x=X[0:1]

predict = model.predict(example)
target_class = np.argmax(predict[0])

last_conv = model.get_layer('conv1d')
grad_model = tf.keras.models.Model([model.inputs], [last_conv.output, model.output])
with tf.GradientTape() as tape:
    conv_outputs, predictions = grad_model(example) 
    loss = predictions[:, target_class]

output = conv_outputs[0]
grads = tape.gradient(loss, conv_outputs)[0]

gradient = grads[:,0]

for i in range(1,64):
  gradient+=grads[:,i]

plt.plot(gradient) 
plt.show() 

gradient_map_image = [gradient,gradient,gradient,gradient,gradient]
plt.imshow(gradient_map_image) # vmin=-1, vmax=1) #cmap='gray
plt.colorbar()

guided_grads = tf.cast(output > 0, 'float32') * tf.cast(grads > 0, 'float32') * grads

guide_grads_example = guided_grads[:,0]
for i in range(1,64):
  guide_grads_example+=guided_grads[:,i]

plt.plot(guide_grads_example) 
plt.show() 

guided_grads_image = [guide_grads_example,guide_grads_example,guide_grads_example, guide_grads_example,guide_grads_example]
plt.imshow(guided_grads_image) # vmin=-1, vmax=1) #cmap='gray
plt.colorbar()

import seaborn as sns
import pandas as pd
from matplotlib import pyplot as plt
from importlib import reload  


values=ds_new.values[0:,0:]

katarameno=pd.DataFrame(ds_new.values[:,:],columns=genes)


katarameno.loc[katarameno.loc[:,'Results']=='stroke','Results']='IS'
katarameno.loc[katarameno.loc[:,'Results']=='control','Results']='Control'



katarameno = katarameno.set_index('Results')

katarameno=katarameno.astype(float)
katarameno = katarameno.sort_index(axis=0)
sns.clustermap(katarameno,figsize=(10, 10))

data = ds_new
print(ds_new)

corr = data.corr()
ax = sns.heatmap(
    corr, 
    vmin=-1, vmax=1, center=0,
    cmap=sns.diverging_palette(20, 220, n=200),
    square=True
)
ax.set_xticklabels(
    ax.get_xticklabels(),
    rotation=45,
    horizontalalignment='right'
);