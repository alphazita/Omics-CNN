# -*- coding: utf-8 -*-
"""Omics-CNN mRMR Covid_19

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_UNqZBDcMsCRdE3KsyGn2267cVJbaDyZ
"""

!pip install Biopython
!pip install git+https://github.com/danielhomola/mifs
!pip install joblib
#η βιβλιοθήκη στο package θέλει joblib χωρίς sklearn γιατί πετάει error
#from joblib.parallel import cpu_count

from google.colab import files 
uploaded = files.upload()

import pandas as pd
import io

ds=pd.read_excel((uploaded['olink_covid_outcome.xlsx']), index_col=None, header=None)
print(ds.shape)
print(ds.head())

from scipy import stats
import numpy as np
ds=np.transpose(ds)
data=np.array(ds.iloc[1:,:])
columns=ds.iloc[0,:]

dataFrame=pd.DataFrame(data,columns=columns)

#Check if more than 30% is empty or null value
dataFrame.isna().sum() /len(dataFrame)

perc = 30.0  # Like N %
min_count =  int(((100-perc)/100)*dataFrame.shape[0] + 1)
dataFrame = dataFrame.dropna(axis=1,thresh=min_count)

#perform Knn for the missing values
from sklearn.impute import KNNImputer

imputer = KNNImputer(n_neighbors=5)
imputed = imputer.fit_transform(dataFrame)
dataFrame = pd.DataFrame(imputed, columns=dataFrame.columns)
dataFrame.isna().sum() /len(dataFrame)

X=dataFrame.drop('Patient outcome',axis=1) 
Y=dataFrame['Patient outcome']
Y=Y.astype('int')

#Εφαρμόζουμε mRMR-test
#def __init__(self, method='MRMR', k=5, n_features='auto', categorical=True,n_jobs=1, verbose=1):
import mifs


# define MI_FS feature selection method
feat_selector = mifs.MutualInformationFeatureSelector(method='MRMR',k=7,n_features='auto',categorical=True,verbose=2)

# find all relevant features
feat_selector.fit(X,Y)
print(feat_selector.ranking_)
selected=feat_selector.ranking_
X_filtered = feat_selector.transform(X)
print('Number of samples',len(X_filtered))
print('Number of genes of each sample',len(X_filtered[0]))

data=[]
columns=dataFrame.columns.tolist()
print(selected)
dataFrame_new=np.transpose(dataFrame)

#Να δεις σε ποια αντιστοιχούν τα χαρακτηριστικά
list2=[]
for i in  selected:
  list2.append(dataFrame.columns[i])
#list2=['UBE2F','VPRBP','TRHR','GNE','RLN2','AP1M1','MYT1L','ICA1L','ST8SIA4','MFAP4','ITSN1','TNFRSF4','KRT15','ARFIP2','GORASP2']
print(list2)
for l in selected:
  k=l-1
  values=dataFrame.iloc[:,l]
  zipped=zip(list2, values) 
  a_dictionary = dict(zipped)
  data.append(values)
ds_new=pd.DataFrame(data)
print(ds_new)

from scipy.cluster.hierarchy import dendrogram, linkage
from plotly.offline import init_notebook_mode, iplot
from Bio.Cluster import treecluster 
import plotly.graph_objs as go
import numpy as np
import matplotlib.pyplot as plt
from collections import Counter, defaultdict

D=ds_new
Z = linkage(D, method='ward', metric='euclidean')
plt.figure(figsize=(10, 6))
ax = plt.subplot()
plt.subplots_adjust(left=0.07, bottom=0.3, right=0.98, top=0.95,wspace=0, hspace=0)
plt.xlabel('Genes')
plt.ylabel('Distance')
d=dendrogram(Z, leaf_rotation=90., leaf_font_size=10.)

from scipy.cluster.hierarchy import leaves_list
list=leaves_list(Z)
print(list)
print (len(list))

import tensorflow as tf
import pandas as pd
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import EarlyStopping,LearningRateScheduler
import keras
from tensorflow.python.keras.layers import Dense,Dropout, Flatten,Conv1D, AveragePooling1D,InputLayer,MaxPooling1D
#from tensorflow.python.keras.optimizers import SGD
from tensorflow.python.keras import Sequential
import numpy as np
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import classification_report
from keras.utils import np_utils
import datetime

df=np.transpose(ds_new)
columns=[list2[i] for i in list]
data=[]

for i in list:
  values=df.iloc[:,i]
  data.append(values)
ds_new=np.transpose(pd.DataFrame(data,columns))
ds_new['Patient outcome']=dataFrame['Patient outcome'].values[:]

genes=ds_new.columns.values.tolist()

# learning rate schedule
import math
#LearningRate = InitialLearningRate * DropRate^floor(Epoch / EpochDrop),floor=the integer not greater than Epoch/EpochDrop
def step_decay(epoch):
	initial_lrate = 0.01
	drop = 0.5
	epochs_drop = 100.0
	lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))
	return lrate
from tensorflow.python.framework.ops import disable_eager_execution

X=ds_new.drop(['Patient outcome'],axis=1)
X=X.values.reshape(X.shape[0],X.shape[1],1)


Y=ds_new['Patient outcome']
Y=Y.astype('int')

model = Sequential()

model.add(Conv1D(filters=64,kernel_size=10, strides=1,activation= 'relu',input_shape=(X.shape[1],1),padding='same'))
model.add(Dropout(0.2))
model.add(MaxPooling1D(pool_size=2))
model.add(Dense(units=500, activation='relu'))
model.add(Dense(units=250, activation='relu'))
model.add(Flatten())
model.add(Dropout(0.2))
model.add(Dense(units=134, activation='relu'))
model.add(Dense(units=2, activation = 'softmax'))

# learning schedule callback
lrate = LearningRateScheduler(step_decay)
# Compile model
print(model.summary())
model.compile( loss='sparse_categorical_crossentropy' , optimizer='sgd', metrics=[ 'accuracy' ])
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)

# Κάνω Stratified Cross Validation για την αξιολόγηση του μοντέλου
from sklearn import model_selection
import matplotlib.pyplot as plt
from scipy import interp
from sklearn.metrics import roc_curve, auc
from sklearn import preprocessing


lb = preprocessing.LabelBinarizer()
Y=ds_new['Patient outcome']
Y=lb.fit_transform(Y)
X=ds_new.drop(['Patient outcome'],axis=1)

k_fold = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)
X=X.values.reshape(X.shape[0],X.shape[1],1)
cvscores=[]

mean_tpr = 0.0
mean_fpr = np.linspace(0, 1, 100)
all_tpr = []
model2=model
i=0

for k_train_index, k_test_index in k_fold.split(X, Y):
  history=model.fit(X[k_train_index,:], Y[k_train_index],validation_data=(X[k_test_index,:],Y[k_test_index]) ,epochs=400,batch_size=30,callbacks=[lrate,es])
  results = model.evaluate(X[k_train_index,:], Y[k_train_index], verbose=0)
  probas_ =model.predict_proba(X[k_test_index,:])
  results = model.evaluate(X[k_train_index,:], Y[k_train_index], verbose=0)
  print('train loss,train acc: ',results)
  results = model.evaluate(X[k_test_index,:],Y[k_test_index], batch_size=30)
  print('test loss, test acc:', results)
  cvscores.append(results[1] * 100)
  # Compute ROC curve and area the curve
  fpr, tpr, thresholds = roc_curve(Y[k_test_index], probas_[:, 1])
  mean_tpr += interp(mean_fpr, fpr, tpr)
  mean_tpr[0] = 0.0
  roc_auc = auc(fpr, tpr)
  plt.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))
  i=i+1

plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')
mean_tpr /= 5
mean_tpr[-1] = 1.0
mean_auc = auc(mean_fpr, mean_tpr)
plt.plot(mean_fpr, mean_tpr, 'k--',label='Mean ROC (area = %0.2f)' % mean_auc, lw=2)

plt.xlim([-0.05, 1.05])
plt.ylim([-0.05, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.show()
##########
  

val_loss, val_acc = model.evaluate(X, Y)
print('Model accuracy of whole dataset as test dataset',val_acc)
y_pred = model.predict(X, batch_size=10, verbose=1)
y_pred_bool = np.argmax(y_pred, axis=1)
print(classification_report(Y, y_pred_bool))
print("Mean performance of model %.2f%% (+/- %.2f%%)" % (np.mean(cvscores), np.std(cvscores)))

example=x=X[0:1]

predict = model.predict(example)
target_class = np.argmax(predict[0])

last_conv = model.get_layer('conv1d')
grad_model = tf.keras.models.Model([model.inputs], [last_conv.output, model.output])
with tf.GradientTape() as tape:
    conv_outputs, predictions = grad_model(example) 
    loss = predictions[:, target_class]

output = conv_outputs[0]
grads = tape.gradient(loss, conv_outputs)[0]

gradient = grads[:,0]

for i in range(1,64):
  gradient+=grads[:,i]

plt.plot(gradient) 
plt.show() 

gradient_map_image = [gradient,gradient,gradient,gradient,gradient]
plt.imshow(gradient_map_image) # vmin=-1, vmax=1) #cmap='gray
plt.colorbar()

guided_grads = tf.cast(output > 0, 'float32') * tf.cast(grads > 0, 'float32') * grads

guide_grads_example = guided_grads[:,0]
for i in range(1,64):
  guide_grads_example+=guided_grads[:,i]

plt.plot(guide_grads_example) 
plt.show() 

guided_grads_image = [guide_grads_example,guide_grads_example,guide_grads_example, guide_grads_example,guide_grads_example]
plt.imshow(guided_grads_image) # vmin=-1, vmax=1) #cmap='gray
plt.colorbar()

import seaborn as sns
import pandas as pd
from matplotlib import pyplot as plt
from importlib import reload  


values=ds_new.values[0:,0:]

katarameno=pd.DataFrame(ds_new.values[:,:],columns=genes)


katarameno.loc[katarameno.loc[:,'Patient outcome']==1,'Patient outcome']='Covid-19'
katarameno.loc[katarameno.loc[:,'Patient outcome']==0,'Patient outcome']='Control'



katarameno = katarameno.set_index('Patient outcome')

katarameno=katarameno.astype(float)
katarameno = katarameno.sort_index(axis=0)
sns.clustermap(katarameno,figsize=(10, 10))

data = ds_new
print(ds_new)

corr = data.corr()
ax = sns.heatmap(
    corr, 
    vmin=-1, vmax=1, center=0,
    cmap=sns.diverging_palette(20, 220, n=200),
    square=True
)
ax.set_xticklabels(
    ax.get_xticklabels(),
    rotation=45,
    horizontalalignment='right'
);