# -*- coding: utf-8 -*-
"""Omics-CNN_Covid_19.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19Jl-v97KeahMpBxIezj9ahlPyiiFZ_ZD
"""

!pip install Biopython

from google.colab import files 
uploaded = files.upload()

import pandas as pd
import io

ds=pd.read_excel((uploaded['olink_covid_outcome.xlsx']), index_col=None, header=None)
print(ds.shape)
print(ds.head())

from scipy import stats
import numpy as np
ds=np.transpose(ds)
data=np.array(ds.iloc[1:,:])
columns=ds.iloc[0,:]

dataFrame=pd.DataFrame(data,columns=columns)
print(dataFrame)
outcome=dataFrame['Patient outcome']

#Check if more than 30% is empty or null value
dataFrame.isna().sum() /len(dataFrame)

perc = 30.0  # Like N %
min_count =  int(((100-perc)/100)*dataFrame.shape[0] + 1)
dataFrame = dataFrame.dropna(axis=1,thresh=min_count)
print(dataFrame.shape)

#perform Knn for the missing values
from sklearn.impute import KNNImputer

imputer = KNNImputer(n_neighbors=5)
imputed = imputer.fit_transform(dataFrame)
dataFrame = pd.DataFrame(imputed, columns=dataFrame.columns)
dataFrame.isna().sum() /len(dataFrame)

print(dataFrame)

from scipy.cluster.hierarchy import dendrogram, linkage
from plotly.offline import init_notebook_mode, iplot
from Bio.Cluster import treecluster 
import plotly.graph_objs as go
import numpy as np
import matplotlib.pyplot as plt
from collections import Counter, defaultdict
from tensorflow.keras.callbacks import EarlyStopping

#D=dataFrame.iloc[1:,:].values
dataframe=(dataFrame.drop(['Patient outcome'],axis=1)).transpose()
list2=dataframe.index.to_list()
#print(list2)
#print(dataframe)
D=dataframe.iloc[:,:].values

Z = linkage(D, method='ward', metric='euclidean')
plt.figure(figsize=(10, 6))
ax = plt.subplot()
plt.subplots_adjust(left=0.07, bottom=0.3, right=0.98, top=0.95,wspace=0, hspace=0)
plt.xlabel('Genes')
plt.ylabel('Distance')
d=dendrogram(Z, leaf_rotation=90., leaf_font_size=10.)

from scipy.cluster.hierarchy import leaves_list
list=leaves_list(Z)
print(list)
print (len(list))

import tensorflow as tf
import pandas as pd
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import EarlyStopping,LearningRateScheduler
import keras
from tensorflow.python.keras.layers import Dense,Dropout, Flatten,Conv1D, AveragePooling1D,InputLayer
from tensorflow.python.keras import Sequential
from tensorflow.keras.optimizers import SGD
import numpy as np
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import classification_report
from keras.utils import np_utils
import datetime
from sklearn.metrics import classification_report

columns=[]
attribute_name=[]
columns=[list2[i] for i in list]
print(columns)
data=[]
df=np.transpose(dataframe)
for i in (list):
  values=df.iloc[:,i]
  data.append(values)
ds_new=np.transpose(pd.DataFrame(data,columns))

ds_new['Patient outcome']=outcome
#print(ds_new)

rows,columns=ds_new.shape



from sklearn import preprocessing
lb = preprocessing.LabelBinarizer()

print(ds_new['Patient outcome'])

# learning rate schedule
import math
#LearningRate = InitialLearningRate * DropRate^floor(Epoch / EpochDrop),floor=the integer not greater than Epoch/EpochDrop
def step_decay(epoch):
	initial_lrate = 0.01
	drop = 0.5
	epochs_drop = 100.0
	lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))
	return lrate
from tensorflow.python.framework.ops import disable_eager_execution

X=ds_new.drop(['Patient outcome'],axis=1)
X=X.values.reshape(X.shape[0],X.shape[1],1)


Y=ds_new['Patient outcome']
Y=Y.astype('int')


model = Sequential()
model.add(Conv1D(filters=64,kernel_size=10, strides=1,activation= 'relu',input_shape=(X.shape[1],1),padding='same'))
model.add(Dropout(0.2))
model.add(AveragePooling1D(pool_size=2))
model.add(Conv1D(64, 10, strides=1,activation= 'relu',padding='same'))
model.add(AveragePooling1D(pool_size=2))
model.add(Dense(units=500, activation='relu'))
model.add(Dense(units=250, activation='relu', name='visualized_layer'))
model.add(Flatten())
model.add(Dropout(0.2))
model.add(Dense(units=134, activation='relu'))
model.add(Dense(units=2, activation = 'softmax'))


sgd = SGD(learning_rate=0.0001)
# Compile model
lrate = LearningRateScheduler(step_decay)
print(model.summary())
#model.compile( loss='mean_squared_error' , optimizer='adam' , metrics=[ 'accuracy' ])
model.compile( loss='sparse_categorical_crossentropy' , optimizer='sgd' , metrics=[ 'accuracy' ])
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)

# Κάνω Stratified Cross Validation για την αξιολόγηση του μοντέλου
from sklearn import model_selection
import matplotlib.pyplot as plt
from sklearn import preprocessing


X=ds_new.drop(['Patient outcome'],axis=1)
print(X.shape)


k_fold = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)
X=X.values.reshape(X.shape[0],X.shape[1],1)
cvscores=[]
y_real = []
y_proba = []


i=0

for k_train_index, k_test_index in k_fold.split(X, Y):
  history=model.fit(X[k_train_index,:], Y[k_train_index],validation_data=(X[k_test_index,:],Y[k_test_index]) ,epochs=400,batch_size=32)
  probas_ =model.predict_proba(X[k_test_index,:])
  results = model.evaluate(X[k_train_index,:], Y[k_train_index], verbose=0)
  print('train loss,train acc: ',results)
  results = model.evaluate(X[k_test_index,:],Y[k_test_index], batch_size=30)
  print('test loss, test acc:', results)
  cvscores.append(results[1] * 100)


val_loss, val_acc = model.evaluate(X, Y)
print('Model accuracy of whole dataset as test dataset',val_acc)
y_pred = model.predict(X, batch_size=10, verbose=1)
y_pred_bool = np.argmax(y_pred, axis=1)
print(classification_report(Y, y_pred_bool,zero_division=1))
print("Mean performance of model %.2f%% (+/- %.2f%%)" % (np.mean(cvscores), np.std(cvscores)))