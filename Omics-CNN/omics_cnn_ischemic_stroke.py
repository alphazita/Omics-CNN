# -*- coding: utf-8 -*-
"""Omics-CNN Ischemic_Stroke.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19XkJdBJeC9UFSwTgeIGVeNxxlxkr2xC0
"""

!pip install Biopython

from google.colab import files 
uploaded = files.upload()

import pandas as pd
import io
#import τις κατάλληλες βιβλιοθήκες και το αρχείο
ds=pd.read_excel(io.BytesIO(uploaded['combined_stroke_normalized - Αντιγραφή.xlsx']))
print(ds.shape)
print(ds.head())

from scipy import stats
import numpy as np
ds=np.transpose(ds)
data=np.array(ds.iloc[1:,1:])
columns=ds.iloc[0,1:]

ds=pd.DataFrame(data,columns=columns)
outcome=ds['Results']
ds.head()

from scipy.cluster.hierarchy import dendrogram, linkage
from plotly.offline import init_notebook_mode, iplot
from Bio.Cluster import treecluster 
import plotly.graph_objs as go
import numpy as np
import matplotlib.pyplot as plt
from collections import Counter, defaultdict
from tensorflow.keras.callbacks import EarlyStopping

dataframe_new=(ds.drop(['Results'],axis=1)).transpose()
list2=dataframe_new.index.to_list()
D=dataframe_new.iloc[:,:].values

Z = linkage(D, method='ward', metric='euclidean')
#print(Z)
print('MHKOS Z',len(Z))
plt.figure(figsize=(10, 6))
ax = plt.subplot()
plt.subplots_adjust(left=0.07, bottom=0.3, right=0.98, top=0.95,wspace=0, hspace=0)
plt.xlabel('Genes')
plt.ylabel('Distance')
d=dendrogram(Z, leaf_rotation=90., leaf_font_size=10.)

from scipy.cluster.hierarchy import leaves_list
list=leaves_list(Z)
print(list)
print (len(list))

import tensorflow as tf
import pandas as pd
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import EarlyStopping,LearningRateScheduler
import keras
from tensorflow.python.keras.layers import Dense,Dropout, Flatten,Conv1D, AveragePooling1D,InputLayer
from tensorflow.python.keras import Sequential
from tensorflow.keras.optimizers import SGD
import numpy as np
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import classification_report
from keras.utils import np_utils
import datetime

columns=[]
attribute_name=[]
columns=[list2[i] for i in list]
print(columns)
data=[]
df=np.transpose(dataframe_new)
for i in (list):
  values=df.iloc[:,i]
  data.append(values)
ds_new=np.transpose(pd.DataFrame(data,columns))

ds_new['Results']=outcome

#print(ds_new)
rows,columns=ds_new.shape

from sklearn import preprocessing
lb = preprocessing.LabelBinarizer()

X=ds_new.drop(['Results'],axis=1)
print(X.shape)
Y=ds_new['Results']
Y=lb.fit_transform(Y)
k_fold = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)
X=X.values.reshape(X.shape[0],X.shape[1],1)

from tensorflow.python.framework.ops import disable_eager_execution
from sklearn.metrics import precision_recall_curve, auc, roc_curve
import matplotlib.pyplot as plt
from scipy import interp
# learning rate schedule
import math
#LearningRate = InitialLearningRate * DropRate^floor(Epoch / EpochDrop),floor=the integer not greater than Epoch/EpochDrop
def step_decay(epoch):
	initial_lrate = 0.01
	drop = 0.5
	epochs_drop = 50
	lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))
	return lrate
disable_eager_execution()

model = Sequential()
model.add(Conv1D(filters=64,kernel_size=10, strides=1,activation= 'relu',input_shape=(X.shape[1],1),padding='same'))
model.add(Dropout(0.2))
model.add(AveragePooling1D(pool_size=2))
model.add(Conv1D(64, 7, strides=1,activation= 'relu'))
model.add(Conv1D(64, 7, strides=1,activation= 'relu'))
model.add(AveragePooling1D(pool_size=2))
model.add(Dense(units=500, activation='relu'))
model.add(Dense(units=250, activation='relu'))
model.add(Flatten())
model.add(Dropout(0.2))
model.add(Dense(units=134, activation='relu'))
#2 διότι δύο τιμές προβλέπει
model.add(Dense(units=2, activation = 'softmax'))
#sgd = optimizers.SGD(lr=0.01,  momentum=0.9)
sgd = SGD(lr=0.00)
# Compile model
lrate = LearningRateScheduler(step_decay)
print(model.summary())
model.compile( loss='sparse_categorical_crossentropy' , optimizer='sgd' , metrics=[ 'accuracy' ])
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)

# Κάνω Stratified Cross Validation για την αξιολόγηση του μοντέλου
from sklearn import model_selection
import matplotlib.pyplot as plt



cvscores=[]
y_real = []
y_proba = []

mean_tpr = 0.0
mean_fpr = np.linspace(0, 1, 100)
all_tpr = []
i=0

for k_train_index, k_test_index in k_fold.split(X, Y):
  history=model.fit(X[k_train_index,:], Y[k_train_index],validation_data=(X[k_test_index,:],Y[k_test_index]) ,epochs=400,batch_size=32)
  #history=model.fit_generator(X[k_train_index,:], Y[k_train_index],validation_data=(X[k_test_index,:],Y[k_test_index]) ,batch_size=30,epochs=400,callbacks=[lrate,es])
  probas_ =model.predict_proba(X[k_test_index,:])
  results = model.evaluate(X[k_train_index,:], Y[k_train_index], verbose=0)
  print('train loss,train acc: ',results)
  results = model.evaluate(X[k_test_index,:],Y[k_test_index], batch_size=30)
  print('test loss, test acc:', results)
  cvscores.append(results[1] * 100)


val_loss, val_acc = model.evaluate(X, Y)
print('Model accuracy of whole dataset as test dataset',val_acc)
y_pred = model.predict(X, batch_size=10, verbose=1)
y_pred_bool = np.argmax(y_pred, axis=1)
print(classification_report(Y, y_pred_bool,zero_division=1))
print("Mean performance of model %.2f%% (+/- %.2f%%)" % (np.mean(cvscores), np.std(cvscores)))